<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.16.4 by Michael Rose
  Copyright 2013-2019 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>            Capacity of Neural Networks (1): Rademacher Complexity - 孙轶同的博客      Yitong’s Blog      </title>
<meta name="description" content="Current sample complexity analysis of supervised learning heavily depends on the capacity analysis of the hypothesis classes. There are many different quantities characterizing the capacity. Among them the most widely used are VC-dimension and Rademacher/Gaussian complexity. In this series of notes, we will first prove some general properties of Rademacher/Gaussian complexity, then the capacity results of neural networks, and finally discuss the relation between VC-dimension and Rademacher complexity.">



<meta property="og:type" content="article">
<meta property="og:locale" content="en">
<meta property="og:site_name" content="孙轶同的博客|Yitong's Blog">
<meta property="og:title" content="Capacity of Neural Networks (1): Rademacher Complexity">
<meta property="og:url" content="https://syitong.github.io/notes/capacity-of-neural-network-1/">


  <meta property="og:description" content="Current sample complexity analysis of supervised learning heavily depends on the capacity analysis of the hypothesis classes. There are many different quantities characterizing the capacity. Among them the most widely used are VC-dimension and Rademacher/Gaussian complexity. In this series of notes, we will first prove some general properties of Rademacher/Gaussian complexity, then the capacity results of neural networks, and finally discuss the relation between VC-dimension and Rademacher complexity.">







  <meta property="article:published_time" content="2018-01-09T00:00:00-05:00">





  

  


<link rel="canonical" href="https://syitong.github.io/notes/capacity-of-neural-network-1/">







  <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "Person",
      "name": "Yitong Sun",
      "url": "https://syitong.github.io",
      "sameAs": null
    }
  </script>







<!-- end _includes/seo.html -->


<link href="https://syitong.github.io/feed.xml" type="application/atom+xml" rel="alternate" title="孙轶同的博客|Yitong's Blog Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- Mathjax support -->

<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


<!-- For all browsers -->
<link rel="stylesheet" href="https://syitong.github.io/assets/css/main.css">

<!--[if lte IE 9]>
  <style>
    /* old IE unsupported flexbox fixes */
    .greedy-nav .site-title {
      padding-right: 3em;
    }
    .greedy-nav button {
      position: absolute;
      top: 0;
      right: 0;
      height: 100%;
    }
  </style>
<![endif]-->

<meta http-equiv="cleartype" content="on">

<!-- Baidu Autopush -->
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>

<!-- Baidu header-->


    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single wide">

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">孙轶同的博客|Yitong's Blog</a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/categories/" >Categories</a>
            </li><li class="masthead__menu-item">
              <a href="/tags/" >Tags</a>
            </li><li class="masthead__menu-item">
              <a href="/years/" >Years</a>
            </li></ul>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle Menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      



<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person">

  
    <div class="author__avatar">
      

      
        <img src="/assets/images/icon128.png" alt="Yitong Sun" itemprop="image">
      
    </div>
  

  <div class="author__content">
    
      <h3 class="author__name" itemprop="name">Yitong Sun</h3>
    
    
      <p class="author__bio" itemprop="description">
        长风破浪会有时
      </p>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
  </div>


  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="Capacity of Neural Networks (1): Rademacher Complexity">
    <meta itemprop="description" content="Current sample complexity analysis of supervised learning heavily depends on the capacity analysis of the hypothesis classes. There are many different quantities characterizing the capacity. Among them the most widely used are VC-dimension and Rademacher/Gaussian complexity. In this series of notes, we will first prove some general properties of Rademacher/Gaussian complexity, then the capacity results of neural networks, and finally discuss the relation between VC-dimension and Rademacher complexity.">
    <meta itemprop="datePublished" content="January 09, 2018">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">Capacity of Neural Networks (1): Rademacher Complexity
</h1>
          
            <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  2 minute read
</p>
          
        </header>
      

      <section class="page__content" itemprop="text">
        
        <p>Current sample complexity analysis of supervised learning heavily depends on the capacity analysis of the hypothesis classes. There are many different quantities characterizing the capacity. Among them the most widely used are VC-dimension and Rademacher/Gaussian complexity. In this series of notes, we will first prove some general properties of Rademacher/Gaussian complexity, then the capacity results of neural networks, and finally discuss the relation between VC-dimension and Rademacher complexity.</p>

<h2 id="rademacher-and-gaussian-complexity">Rademacher and Gaussian Complexity</h2>

<p>In this note, we use <script type="math/tex">\{\sigma_i\}</script> for a list of independent Rademacher random variables and <script type="math/tex">\{g_i\}</script> for a list of independent Gaussian random variables. The so-called empirical process, which is the Banach-space-indexed random variables, has been studied intensively to understand properties of Banach spaces. It is defined in the following way,</p>

<script type="math/tex; mode=display">\begin{equation*}
X = \sum_{i=1}^{m} g_i x_i~,
\end{equation*}</script>

<p>where <script type="math/tex">x_i</script>s are vectors in a Banach space <script type="math/tex">\mathcal{B}</script>. We are interested in the expectation of <script type="math/tex">\Vert X\Vert</script>. For the quantity to be well defined; that is, measurable and integrable etc., some assumptions have to be made carefully. See <a class="citation" href="#Ledoux1991">(Ledoux &amp; Talagrand, 1991)</a> for details. We will not worry about these sophisticated aspects in the theory.</p>

<p>In our setup, the space is defined by <script type="math/tex">\mathcal{H}(\mathbb{R}^d):=\{(h(x))_{h\in\mathcal{H}}\mid x\in\mathbb{R}^d\}</script>. Together with the quantity playing the role of norm in Banach space</p>

<script type="math/tex; mode=display">\begin{equation*}
\Vert (h(x))_{h\in\mathcal{H}}\Vert := \sup_{h\in\mathcal{H}} h(x)\,,
\end{equation*}</script>

<p><script type="math/tex">(\mathcal{H}(\mathbb{R}^d),\Vert\cdot\Vert)</script> is a space analogous to the Banach space, although not quite the same. <script type="math/tex">\ell_\infty</script> is a special case of the space we defined above, which is also a Banach space. For simplicity, we will denote <script type="math/tex">(h(x))_{h\in\mathcal{H}}</script> by <script type="math/tex">\mathcal{H}(x)</script>.</p>

<p>The Rademacher complexity <script type="math/tex">\mathfrak{R}_m(\mathcal{H})</script> is defined by <script type="math/tex">\frac{1}{m}\mathbb{E}\Vert\sum_{i=1}^m \sigma_i \mathcal{H}(x_i)\Vert</script>, and similarly the Gaussian complexity <script type="math/tex">\mathfrak{G}_m(\mathcal{H})</script> is defined by <script type="math/tex">\frac{1}{m}\mathbb{E}\Vert\sum_{i=1}^m g_i \mathcal{H}(x_i)\Vert</script>. By Azuma’s inequality with bounded difference condition, the sample complexity of ERM over some hypothesis class <script type="math/tex">\mathcal{H}</script> is controlled by the Rademacher/Gaussian complexity of the hypothesis class. In the study of fast learning rate, with extra conditions and more powerful Talagrand’s inequality, the sample complexity is also converted to the control on Rademacher/Gaussian complexity.</p>

<h2 id="equivalence-between-mathfrakr_m-and-mathfrakg_m">Equivalence Between <script type="math/tex">\mathfrak{R}_m</script> and <script type="math/tex">\mathfrak{G}_m</script></h2>

<p>First, let’s show the equivalence of these two quantities; that is,</p>

<script type="math/tex; mode=display">\begin{equation*}
c\mathfrak{R}_m(\mathcal{H}) \le \mathfrak{G}_m(\mathcal{H}) \le C\sqrt{\log(m)} \mathfrak{R}_m(\mathcal{H})~.
\end{equation*}</script>

<p>For the left part, we need the trick <script type="math/tex">g_i \sim \vert g_i\vert \sigma_i</script>. So</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align*}
\mathfrak{G}_m(\mathcal{H}) & =\frac{1}{m}\mathbb{E}\left\Vert\sum_{i=1}^m \sigma_i \vert g_i\vert \mathcal{H}(x_i) \right\Vert \\
	& \ge \frac{1}{m}\mathbb{E} \left\Vert \mathbb{E}_{g} \sum\sigma_i \vert g_i\vert \mathcal{H}(x_i) \right\Vert \tag{Jensen}\\
	& = c\mathfrak{R}_m(\mathcal{H})~,
\end{align*} %]]></script>

<p>where <script type="math/tex">c=\mathbb{E}\vert g\vert</script>.</p>

<p>For the right part, note that <script type="math/tex">g_i \sim g_i\sigma_i</script>. So</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align*}
\mathfrak{G}_m(\mathcal{H}) & =\frac{1}{m}\mathbb{E}\left\Vert\sum_{i=1}^m \sigma_i g_i \mathcal{H}(x_i) \right\Vert \\
	& = \frac{1}{m}\mathbb{E}\left\Vert\sum \max_i{\vert g_i\vert }\frac{g_i}{\max_i{\vert g_i\vert }}\sigma_i \mathcal{H}(x_i) \right\Vert \\
	& = \frac{1}{m}\mathbb{E}_g \max_i \vert g_i\vert  \mathbb{E}_\sigma\left\Vert\sum \frac{g_i}{\max_i{\vert g_i\vert }}\sigma_i \mathcal{H}(x_i) \right\Vert~.
\end{align*} %]]></script>

<p>Here we need Kahane contraction principle,</p>

<script type="math/tex; mode=display">\begin{equation*}
\mathbb{E}_\sigma\left\Vert\sum c_i\sigma_i \mathcal{H}(x_i)\right\Vert \le \mathbb{E}_\sigma\Vert\sum\sigma_i\mathcal{H}(x_i)\Vert~,
\end{equation*}</script>

<p>where <script type="math/tex">\vert c_i\vert \le 1</script>. To see why this is true, we only need to note that the function</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align*}
f: C & \to\mathbb{R} \\
\vec{c} & \mapsto \Vert\sum c_i\sigma_i \mathcal{H}(x_i)\Vert \\
\end{align*} %]]></script>

<p>is convex over the unit cube <script type="math/tex">C</script> for any fixed <script type="math/tex">\sigma_i</script>. Therefore the function attains its maximum at extreme points; that is <script type="math/tex">\vert c_i\vert =1</script>. And since <script type="math/tex">\sigma_i</script> is symmetric and independent, <script type="math/tex">\sigma_i</script>s and <script type="math/tex">-\sigma_i</script>s have the same independent distribution. So by Kahane contraction principle, we have</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align*}
\mathfrak{G}_m{\mathcal{H}} & \le \frac{1}{m}\mathbb{E}_g\max_i\vert g_i\vert \mathbb{E}_\sigma\left\Vert\sum\sigma_i \mathcal{H}(x_i)\right\Vert \\
	& \le \frac{C\sqrt{\log m}}{m}\mathfrak{R}_m(\mathcal{H})~.
\end{align*} %]]></script>

<p>The last inequality holds by upper bounding the <script type="math/tex">\psi_2</script> norm of <script type="math/tex">\max_i\vert g_i\vert</script>.</p>

<h2 id="different-variants-of-mathfrakr_m">Different Variants of <script type="math/tex">\mathfrak{R}_m</script></h2>

<p>There are several different definitions of Rademacher and Gaussian complexity. A very common variant takes the definition</p>

<script type="math/tex; mode=display">\begin{equation*}
\mathfrak{R}_m(\mathcal{H}) := \frac{1}{m}\mathbb{E}\sup_{h\in\mathcal{H}} \left\vert \sum_{i=1}^m \sigma_ih(x_i)\right\vert \,,
\end{equation*}</script>

<p>or denoted by <script type="math/tex">\vert \mathfrak{R}_m\vert (\mathcal{H})</script>. If <script type="math/tex">\mathcal{H}</script> is symmetric; that is <script type="math/tex">h\in\mathcal{H}\implies -h\in\mathcal{H}</script>, <script type="math/tex">\mathfrak{R}_m(\mathcal{H})=\vert \mathfrak{R}_m\vert (\mathcal{H})</script>. Otherwise, <script type="math/tex">\mathfrak{R}_m(\mathcal{H}) \le \vert \mathfrak{R}_m\vert (\mathcal{H})</script>, and <script type="math/tex">\vert \mathfrak{R}_m\vert (\mathcal{H}) = \mathfrak{R}_m(\mathcal{H}\cup-\mathcal{H})\le 2\mathfrak{R}_m(\mathcal{H})</script>. Therefore, these two definitions are equivalent. Our definition however, enjoys a better contraction property when the hypothesis class is composed with a Lipschitz loss function.</p>

<p>Another possible variant of the definition is</p>

<script type="math/tex; mode=display">\begin{equation*}
\mathfrak{R}_{m,p}(\mathcal{H}) := \frac{1}{m}\left[\mathbb{E}\sup_{h\in\mathcal{H}}\left(\sum_{i=1}^m \sigma_ih(x_i)\right)^p\right]^{1/p}\,,
\end{equation*}</script>

<p>for <script type="math/tex">p>1</script>. Clearly this is strictly greater than <script type="math/tex">\mathfrak{R}_m</script> and not useful whenever <script type="math/tex">\mathfrak{R}_m</script> gets controlled.</p>

<h2 id="reference">Reference</h2>
<hr />
<ol class="bibliography"><li><span id="Ledoux1991">Ledoux, M., &amp; Talagrand, M. (1991). <i>Probability in Banach Spaces: Isoperimetry and Processes</i>. Springer Berlin Heidelberg.</span></li></ol>

        
      </section>

      <footer class="page__meta">
        
        
  


  
  
  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      
      
      <a href="/tags/neural-network" class="page__taxonomy-item" rel="tag">neural network</a><span class="sep">, </span>
    
      
      
      <a href="/tags/statistical-learning" class="page__taxonomy-item" rel="tag">statistical learning</a>
    
    </span>
  </p>




  


  
  
  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> Categories: </strong>
    <span itemprop="keywords">
    
      
      
      <a href="/categories/notes" class="page__taxonomy-item" rel="tag">notes</a>
    
    </span>
  </p>


        
          <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated:</strong> <time datetime="2018-01-09T00:00:00-05:00">January 09, 2018</time></p>
        
      </footer>

      <section class="page__share">
  
    <h4 class="page__share-title">Share on</h4>
  

  <a href="https://twitter.com/intent/tweet?text=Capacity+of+Neural+Networks+%281%29%3A+Rademacher+Complexity%20https%3A%2F%2Fsyitong.github.io%2Fnotes%2Fcapacity-of-neural-network-1%2F" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fsyitong.github.io%2Fnotes%2Fcapacity-of-neural-network-1%2F" class="btn btn--facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Facebook"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=https%3A%2F%2Fsyitong.github.io%2Fnotes%2Fcapacity-of-neural-network-1%2F" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


      
  <nav class="pagination">
    
      <a href="/notes/spectrum-Gaussian/" class="pagination--pager" title="On the Spectrum Decay Rate of Gaussian Kernel Operator
">Previous</a>
    
    
      <a href="/notes/capacity-of-neural-networks-2/" class="pagination--pager" title="Capacity of Neural Networks (2): Contraction Inequality
">Next</a>
    
  </nav>

    </div>

    
  </article>

  
  
    <div class="page__related">
      <h4 class="page__related-title">You May Also Enjoy</h4>
      <div class="grid__wrapper">
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/notes/sort-select/" rel="permalink">快速排序与快速选择算法
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  less than 1 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">之所以突然会对这个问题感兴趣是因为，大概一年前，在毫无准备的情况下去参加某互联网公司的面试，被问到了这样一个问题：“给定一个长度为n的数列，如何快速的找出其中第m大的元素。假设m远小于n。”因为对排序和选择算法完全不熟悉，只知道quicksort的时间复杂度应该是，以及从数列中找出最大值的复杂度是 。只好回答最简...</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/articles/rff-intro/" rel="permalink">What Is Random Fourier Features Method?
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  2 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">Random Fourier features method, or more general random features method is a method to help transform data which are not linearly separable to linearly separa...</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/articles/tmux-rename/" rel="permalink">如何阻止ssh重命名tmux窗口
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  less than 1 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">在使用tmux多窗口终端时，每次登录学校的服务器后，窗口的标签就会被改成与服务器的prompt相同。而且登出后也不会改回来，导致tmux经常几个窗口的名字都很长，也没有反映窗口当时的状况。之所以会这样，是因为tmux默认允许一些进程修改窗口名，而ssh对终端窗口的命名规则是由服务器上的配置文件决定的。

</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/articles/cb-setup/" rel="permalink">HiDPI Chromebook上Crouton的设置
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  less than 1 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">入手HP Chromebook 13 g1大半年，一开始就安装了Gallium OS。但Gallium OS迟迟无法解决intel skylake model上的音频输出问题，加上Gallium OS的电源管理比Chrome OS要弱不少，不接电源的情况下无法长时间的使用。忍了大半年后，终于回到了Crouton的...</p>
  </article>
</div>

        
      </div>
    </div>
  
  
</div>

    </div>

    

    <div class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    

    

    <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2019 Yitong Sun. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>
  <script defer src="https://use.fontawesome.com/releases/v5.8.2/js/all.js" integrity="sha384-DJ25uNYET2XCl5ZF++U8eNxPWqcKohUUBUpKGlNLMchM7q4Wjg2CUpjHLaL8yYPH" crossorigin="anonymous"></script>










  </body>
</html>
